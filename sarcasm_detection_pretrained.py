# -*- coding: utf-8 -*-
"""Sarcasm-Detection-pretrained.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/15zgOGUlQxx0YziwFR2Ip5_UfjzzpuRsM

# NLP - Sarcasm Detection
MLP Model + **Pre-trained** Embedding Layer
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from tensorflow.keras import Sequential
from tensorflow.keras import layers
import tensorflow as tf
import tensorflow_hub as hub
from tensorflow import keras
import nltk
from nltk.corpus import stopwords

nltk.download('stopwords')

"""## 1- Load Data"""

!wget --no-check-certificate https://storage.googleapis.com/learning-datasets/sarcasm.json

df = pd.read_json('sarcasm.json')

df.head()

df.shape

sentences = df['headline'].to_list()
labels = df['is_sarcastic'].to_list()

"""## 2- Pre-processing"""

sw = stopwords.words('english')

print(sw)

for s in sentences[:2]:
  print(s)

for i in range(len(sentences)):
  words = sentences[i].split()
  words_new = [w for w in words if w not in sw]
  sentences[i] = ' '.join(words_new)

for s in sentences[:2]:
  print(s)

training_size = 23000

train_sentences = sentences[:training_size]
validation_sentences = sentences[training_size:]

train_labels = labels[:training_size]
validation_labels = labels[training_size:]

train_sentences = np.array(train_sentences)
validation_sentences = np.array(validation_sentences)
train_labels = np.array(train_labels)
validation_labels = np.array(validation_labels)

"""## 3- Model Design"""

hub_layer = hub.KerasLayer("https://www.kaggle.com/models/google/gnews-swivel/frameworks/TensorFlow2/variations/tf2-preview-20dim/versions/1", output_shape=[20],
                           input_shape=[], dtype=tf.string, trainable=False)

model2 = Sequential([
    hub_layer,
    layers.Dense(16, activation='relu'),
    layers.Dense(1, activation='sigmoid')
])

model2.summary()

"""## 4- Training"""

adam = keras.optimizers.Adam(learning_rate=0.0001)
model2.compile(loss='binary_crossentropy', optimizer=adam, metrics=['accuracy'])

history2 = model2.fit(train_sentences, train_labels,
                      batch_size=128,
                      epochs=50,
                      validation_data=(validation_sentences, validation_labels))

def plot_graphs(history, string):
  plt.plot(history.history[string])
  plt.plot(history.history['val_'+string])
  plt.xlabel("Epochs")
  plt.ylabel(string)
  plt.legend([string, 'val_'+string])
  plt.show()

plot_graphs(history2, "accuracy")
plot_graphs(history2, "loss")

test_sentences = ["granny starting to fear spiders in the garden might be real",
                  "game of thrones season finale showing this sunday night",
                  "TensorFlow book will be a best seller"]
# Remove stop-words

preds = model2.predict(test_sentences)
print(preds)